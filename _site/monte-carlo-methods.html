<!DOCTYPE html>
<html lang="en">

	<head>
		<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1" />


	<title>Monte Carlo Methods</title>


<meta name="twitter:card" content="summary" />
<meta name="twitter:site" content="@" />
<meta name="twitter:title" content="Monte Carlo Methods" />
<meta name="twitter:description" content="">

<meta name="description" content="">


	<meta name="google-site-verification" content="epFgX0s_0RM3CdjwFcsewfXzPov2g8s9ZBOLyaIUH-o">


<link rel="icon" href="/assets/favicon.png">
<link rel="apple-touch-icon" href="/assets/touch-icon.png">
<link href="https://fonts.googleapis.com/css?family=Karla" rel="stylesheet">
<link rel="stylesheet" href="/assets/core.css">
<link rel="canonical" href="/monte-carlo-methods">
<link rel="alternate" type="application/atom+xml" title="Lei Zhou's Blog" href="/feed.xml" />




<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>


		<link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
		<style>
			#taglist {
				color: gray;
				margin: 0;
				margin-top: 16px;
				padding: 0;
				list-style-type: none;
				text-align: center;
				vertical-align: middle;
			}
			#taglist li {
				display: inline;
			}
			#taglist li + li:before {
				content: ", ";
			}
		</style>

		<!-- Google Tag Manager -->
		<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
			new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
			j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
			'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
			})(window,document,'script','dataLayer','GTM-T5S7PZV');</script>
		<!-- End Google Tag Manager -->
	</head>

	<body>
		<!-- Google Tag Manager (noscript) -->
		<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-T5S7PZV"
			height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
		<!-- End Google Tag Manager (noscript) -->

		
<aside class="logo">

	

	<a href="/">
		<img src="/images/avatar.jpeg" class="gravatar">
	</a>
	<span class="logo-prompt">Back to Home</span>

</aside>


		<main>
			<noscript>
	<style>
		article .footnotes {
			display: block;
		}
	</style>
</noscript>

<article>
	<div class="center">
		<h1>Monte Carlo Methods</h1>
		<time>April 22, 2018</time>
		<ul id="taglist">
			Tag:
			
		</ul>
	</div>

	<div class="divider"></div>

	<ul id="markdown-toc">
  <li><a href="#overview" id="markdown-toc-overview">Overview</a></li>
  <li><a href="#draw-random-samples-uniformly-over-the-cumulative-distribution-function-cdf" id="markdown-toc-draw-random-samples-uniformly-over-the-cumulative-distribution-function-cdf">Draw random samples uniformly over the cumulative distribution function (CDF)</a></li>
  <li><a href="#markov-chain-monte-carlo-mcmc" id="markdown-toc-markov-chain-monte-carlo-mcmc">Markov Chain Monte-Carlo (MCMC)</a>    <ul>
      <li><a href="#glossary" id="markdown-toc-glossary">Glossary</a></li>
      <li><a href="#metropolishastings-algorithm" id="markdown-toc-metropolishastings-algorithm">Metropolis–Hastings algorithm</a></li>
      <li><a href="#gibbs-sampling" id="markdown-toc-gibbs-sampling">Gibbs sampling</a></li>
      <li><a href="#metropolis-within-gibbs-hybrid-gibbs" id="markdown-toc-metropolis-within-gibbs-hybrid-gibbs">Metropolis within Gibbs (Hybrid Gibbs)</a></li>
      <li><a href="#hamiltonian-monte-carlo-hybrid-monte-carlo" id="markdown-toc-hamiltonian-monte-carlo-hybrid-monte-carlo">Hamiltonian Monte Carlo (Hybrid Monte Carlo)</a></li>
      <li><a href="#adaptive-rejection-sampling" id="markdown-toc-adaptive-rejection-sampling">Adaptive rejection sampling</a></li>
      <li><a href="#cluster-sampling" id="markdown-toc-cluster-sampling">Cluster sampling</a></li>
      <li><a href="#random-walk" id="markdown-toc-random-walk">Random Walk</a></li>
      <li><a href="#convergence" id="markdown-toc-convergence">Convergence</a></li>
    </ul>
  </li>
  <li><a href="#reference" id="markdown-toc-reference">Reference</a></li>
</ul>

<h1 id="overview">Overview</h1>

<h1 id="draw-random-samples-uniformly-over-the-cumulative-distribution-function-cdf">Draw random samples uniformly over the cumulative distribution function (CDF)</h1>

<h1 id="markov-chain-monte-carlo-mcmc">Markov Chain Monte-Carlo (MCMC)</h1>

<p>Markov chain Monte-Carlo uses a homogeneous, ergodic and reversible (see [1] for the meaning of the adjectives) Markov chain to generate consistent samples draw from any given distribution.</p>

<h3 id="glossary">Glossary</h3>

<ul>
  <li>
    <p>Stationary. A markov chain is stationary if <script type="math/tex">P(x_{t+1} \| x_t)</script> does not depend on <script type="math/tex">t</script>.</p>
  </li>
  <li>
    <p>Ergodic. A markov chain is ergodic if <script type="math/tex">x_t</script> converges to a distribution not matter what the starting value is.</p>
  </li>
  <li>
    <p>Irreducible. A markov chain is irreducible if the samples of the chain can move all over the state space, i.e., can eventually reach any region of the state space, no matter its initial value.</p>
  </li>
  <li>
    <p>Aperiodic. Sampling不会周期性地回到某个点.</p>
  </li>
</ul>

<h3 id="metropolishastings-algorithm">Metropolis–Hastings algorithm</h3>

<ol>
  <li>
    <p>Given <script type="math/tex">X_t=x_t</script>, generate <script type="math/tex">Y_t \sim q(y \| x_t)</script>, where the conditional density <script type="math/tex">q(y \| x)</script> is called <strong>proposal</strong>, which is used to generate next sample.</p>
  </li>
  <li>
    <p>Take <script type="math/tex">X^{t+1} = Y^t</script> with probability <script type="math/tex">\rho(x^t, Y^t)</script>  or <script type="math/tex">X^{t+1} = x^t</script> with probability <script type="math/tex">1 - \rho(x^t, Y^t)</script>, where <script type="math/tex">\rho(x, y) = \min\{ \frac{\pi(y)}{\pi(x)} \frac{q(x\|y)}{q(y\|x)}, 1 \}</script>. Here we do not need to obtain the exact value of <script type="math/tex">\pi(y)</script> and <script type="math/tex">\pi(x)</script>, but more easily, their ratio.</p>
  </li>
</ol>

<p>(The proposal <script type="math/tex">q(y \| x)</script> must be carefully chosen to ensure that the samples of MCMC converge to the target distribution <script type="math/tex">\pi(x)</script>.)</p>

<h3 id="gibbs-sampling">Gibbs sampling</h3>

<p>Gibbs sampling is a multivariate version of Metropolis–Hastings algorithm. Here we consider the multivariate distribution of <script type="math/tex">\mathbf{X} = (x_1, ..., x_n)</script>.</p>

<p>In the transition step （step 2 above）, we generate next proposal <script type="math/tex">\mathbf{X}^{t+1}</script> from <script type="math/tex">\mathbf{X}^t</script> based on the conditional density <script type="math/tex">q(x_j^{t+1} \| x_1^{t+1}, ..., x_{j-1}^{t+1}, x_{j+1}^{t}, ..., x_n^{t})</script>, since the variables are correlated. It means the <script type="math/tex">j</script>th component <script type="math/tex">x_j^{t+1}</script> is conditioned on all the other components at hand.</p>

<h3 id="metropolis-within-gibbs-hybrid-gibbs">Metropolis within Gibbs (Hybrid Gibbs)</h3>

<p>Metropolis within Gibbs uses the Metropolis Hasting proposal for each component of <script type="math/tex">\mathbf{X}^{t+1}</script>.</p>

<p><a href="http://www.chadfulton.com/fulton_statsmodels_2017/sections/5-posterior_simulation.html">http://www.chadfulton.com/fulton_statsmodels_2017/sections/5-posterior_simulation.html</a></p>

<h3 id="hamiltonian-monte-carlo-hybrid-monte-carlo">Hamiltonian Monte Carlo (Hybrid Monte Carlo)</h3>

<p>Hamiltonian dynamics是一种物理学上的动态过程,描述了一个有质量的物体的势能和动能的相互转化.想像一个固定在弹簧末端的小球,在小球左右来回摆动时,小球的动能和弹簧的弹性势能相互转化.其中弹性势能的计算取决于小球的位置<script type="math/tex">x</script>,动能的计算取决于小球的动量<script type="math/tex">p=mv</script>,这两个值<script type="math/tex">(x,p)</script>定义了Hamiltonian dynamics动态过程的一个坐标.随着时间的变化,每一个时间点的坐标可以通过积分的方法计算得到.例如,Leap Frog Method就是一个将连续时间离散为很小的时间段计算每个离散时间点<script type="math/tex">(x,p)</script>的方法.
对于一个分布来讲,不同的位置<script type="math/tex">(x,p)</script>的总能量(势能+动能)是不同的,能量的大小反映了概率分布.对于MAP问题,就是要找能量最低的那个点.</p>

<p>在Hamiltonian Monte Carlo(HMC)采样中,Hamiltonian dynamics被用来生成下一个proposal - <script type="math/tex">x</script>.此时的energy funciton定义为势能和动能之和,即<script type="math/tex">H(x,p)=U(x)+K(p)</script>.采样点<script type="math/tex">(x,p)</script>的概率为<script type="math/tex">P(x,p)=\frac{1}{Z}e^{-U(x)-K(p)}</script>.整个proposal的过程如下:</p>

<ol>
  <li>在第<script type="math/tex">t</script>步,给定一个采样<script type="math/tex">x_t</script>,从变量<script type="math/tex">p</script>的标准分布<script type="math/tex">P(p)</script>(canonical distribution,人为定义)中随机采样一个值<script type="math/tex">p_t</script>构成坐标<script type="math/tex">(x_t, p_t)</script>.</li>
  <li>跑<script type="math/tex">L</script>步的Leap Frog Method来模拟Hamiltonian dynamics动态过程,到达结束位置<script type="math/tex">(x*, p*)</script></li>
  <li>比较<script type="math/tex">H(x_t,p_t)</script>和<script type="math/tex">H(x*,p*)</script>的相对大小,按照Metropolis–Hastings algorithm的方法accept或者reject,从而得到<script type="math/tex">(x_{t+1}, p_{t+1})</script>.</li>
</ol>

<p>在每一步生成proposal时,因为引入了随机动量<script type="math/tex">p_t</script>,所以HMC可以有效地探索整个分布空间.
因为HMC相邻两个采样的距离比Metropolis–Hastings algorithm更大,且相关性(autocorrelation)更小,所以有更快的收敛效果.</p>

<p>详细讲解和示例见:<a href="https://theclevermachine.wordpress.com/2012/11/18/mcmc-hamiltonian-monte-carlo-a-k-a-hybrid-monte-carlo/">https://theclevermachine.wordpress.com/2012/11/18/mcmc-hamiltonian-monte-carlo-a-k-a-hybrid-monte-carlo/</a></p>

<h3 id="adaptive-rejection-sampling">Adaptive rejection sampling</h3>

<p>The main idea is to asymptotically optimize the transition function to minimize the rejection rate.</p>

<h3 id="cluster-sampling">Cluster sampling</h3>

<p>It split an image into individual clusters, which is useful for image segmentation.</p>

<p><a href="https://pdfs.semanticscholar.org/4256/35f354bab06f3811eb0093d67ba37445fe12.pdf">Interpretations of Cluster Sampling by Swendsen-Wang</a></p>

<h3 id="random-walk">Random Walk</h3>
<p><a href="http://www.cs.bu.edu/~snyder/cs109/CS109.Lect15.pdf">Google Page Rank via random walk</a></p>

<h2 id="convergence">Convergence</h2>

<p>The structural properties required for a constructed chain to converge appropriately are well understood: essentially irreducibility and aperiodicity.</p>

<h1 id="reference">Reference</h1>
<p>[1] <a href="https://www.unige.ch/sciences/astro/files/2713/8971/4086/3_Paltani_MonteCarlo.pdf">Lecture notes</a></p>

<p>[2] <a href="http://www.mcmchandbook.net/HandbookChapter1.pdf">Introduction to Markov Chain Monte Carlo</a></p>

<p>[3] Very useful for the newers: <a href="https://link.springer.com/content/pdf/10.3758%2Fs13423-016-1015-8.pdf">A simple introduction to Markov Chain Monte–Carlo sampling</a></p>

<p>[3] <a href="http://www.deeplearningbook.org/contents/monte_carlo.html">Deep Learning Book</a></p>



</article>

<div class="page-navigation">
	
    <a class="next" href="/optimization-for-least-square-problem" title="NEXT: Optimization for Least Square Problems">&lt;&lt;</a>
		<span> &middot; </span>
  
		<a class="home" href="/" title="Back to Homepage">Home</a>
  
		<span> &middot; </span>
    <a class="prev" href="/Geometry" title="PREV: Geometry">&gt;&gt;</a>
  
</div>

		</main>
                                                      

		<div class="footer">
<!--  <span class="block">Made with &hearts; using <a href="http://jekyllrb.com/">Jekyll</a> &amp; <a href="https://github.com/heiswayi/the-plain" title="Lei's Blog">The Plain</a> &middot; &lt;/&gt; on <a href="https://github.com/zlthinker" title="Hosted on GitHub">GitHub</a></span> -->
  <span class="block">&copy; 2018 Lei ZHOU</span>
</div>


		

			

		

		<!-- hit counter -->
		<br>
		<center>
		<img src="http://hitwebcounter.com/counter/counter.php?page=6818827&style=0024&nbdigits=5&type=ip&initCount=0" align="top" title="" Alt=""   border="1" height=18px/>    
		</center>  

	</body>

</html>
