<!DOCTYPE html>
<html lang="en">

	<head>
		<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1" />


	<title>Deep Learning</title>


<meta name="twitter:card" content="summary" />
<meta name="twitter:site" content="@" />
<meta name="twitter:title" content="Deep Learning" />
<meta name="twitter:description" content="">

<meta name="description" content="">


	<meta name="google-site-verification" content="epFgX0s_0RM3CdjwFcsewfXzPov2g8s9ZBOLyaIUH-o">


<link rel="icon" href="/assets/favicon.png">
<link rel="apple-touch-icon" href="/assets/touch-icon.png">
<link href="https://fonts.googleapis.com/css?family=Karla" rel="stylesheet">
<link rel="stylesheet" href="/assets/core.css">
<link rel="canonical" href="/deep-learning">
<link rel="alternate" type="application/atom+xml" title="Lei Zhou's Blog" href="/feed.xml" />




<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>


		<link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
		<style>
			#taglist {
				color: gray;
				margin: 0;
				margin-top: 16px;
				padding: 0;
				list-style-type: none;
				text-align: center;
				vertical-align: middle;
			}
			#taglist li {
				display: inline;
			}
			#taglist li + li:before {
				content: ", ";
			}
		</style>

		<!-- Google Tag Manager -->
		<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
			new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
			j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
			'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
			})(window,document,'script','dataLayer','GTM-T5S7PZV');</script>
		<!-- End Google Tag Manager -->
	</head>

	<body>
		<!-- Google Tag Manager (noscript) -->
		<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-T5S7PZV"
			height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
		<!-- End Google Tag Manager (noscript) -->

		
<aside class="logo">

	

	<a href="/">
		<img src="/images/avatar.jpeg" class="gravatar">
	</a>
	<span class="logo-prompt">Back to Home</span>

</aside>


		<main>
			<noscript>
	<style>
		article .footnotes {
			display: block;
		}
	</style>
</noscript>

<article>
	<div class="center">
		<h1>Deep Learning</h1>
		<time>March 24, 2018</time>
		<ul id="taglist">
			Tag:
			
				<li><a href="/tag_index.html" title="deep learning">deep learning</a></li>
			
		</ul>
	</div>

	<div class="divider"></div>

	<ul id="markdown-toc">
  <li><a href="#transfer-learning" id="markdown-toc-transfer-learning">Transfer Learning</a></li>
  <li><a href="#lstm" id="markdown-toc-lstm">LSTM</a></li>
  <li><a href="#networks--architectures" id="markdown-toc-networks--architectures">Networks &amp; Architectures</a>    <ul>
      <li><a href="#cnn-networks" id="markdown-toc-cnn-networks">CNN Networks</a></li>
      <li><a href="#dilated-convolution-空洞卷积扩张卷积" id="markdown-toc-dilated-convolution-空洞卷积扩张卷积">Dilated convolution (空洞卷积,扩张卷积)</a></li>
      <li><a href="#deconvolution-反卷积" id="markdown-toc-deconvolution-反卷积">Deconvolution (反卷积)</a></li>
      <li><a href="#unpooling" id="markdown-toc-unpooling">Unpooling</a></li>
    </ul>
  </li>
  <li><a href="#loss" id="markdown-toc-loss">Loss</a>    <ul>
      <li><a href="#focal-loss-2" id="markdown-toc-focal-loss-2">focal loss [2]</a></li>
    </ul>
  </li>
  <li><a href="#visualization" id="markdown-toc-visualization">Visualization</a></li>
  <li><a href="#platform" id="markdown-toc-platform">Platform</a></li>
  <li><a href="#reference" id="markdown-toc-reference">Reference</a></li>
</ul>

<h1 id="transfer-learning">Transfer Learning</h1>

<p>Transfer learning is dedicated to transfer the knowledge gained from one task to solving other related problems instead of learning from scratch. 
In the field of data representation, an assumption is that the training and future data must be in the same feature space and have the same distribution (actualy they are). In practice, transfer learning has been applied in model initialization whose parameters are shared by different applications like classification, detection, recognition and regression.</p>

<h1 id="lstm">LSTM</h1>

<p><a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/">This</a> excellent post makes me give up writing.</p>

<p><a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/">RNN</a></p>

<h1 id="networks--architectures">Networks &amp; Architectures</h1>

<h3 id="cnn-networks"><a href="/CNN-networks">CNN Networks</a></h3>

<h3 id="dilated-convolution-空洞卷积扩张卷积">Dilated convolution (空洞卷积,扩张卷积)</h3>

<p><img src="/images/dilated_conv.jpg" alt="dilated_conv" />
上图(a)(b)(c)分别是3x3的1-dilated, 2-dilated, 4-dilated conv. Dilated conv设计的目的是不会增加参数的数量的同时增加感受野. 尤其是将(a)(b)(c)级联起来之后,感受野由3x3增加到7x7,再增加到15x15.</p>

<h3 id="deconvolution-反卷积">Deconvolution (反卷积)</h3>

<p>考虑一个4x4的feature map, 经过一个padding 0, stride 1, 3x3的卷积核后变成2x2的feature map, 卷积操作的矩阵运算表达形式为 <script type="math/tex">\mathbf{y}_{4\times1}=\mathbf{C}_{4\times16} \mathbf{x}_{16\times1}</script>. 卷积矩阵<script type="math/tex">\mathbf{C}</script>的表达式如下:</p>

<p><img src="/images/conv_mat.jpg" alt="conv_mat" /></p>

<p>反卷积数学上其实就是卷积矩阵的转置, 反卷积操作可以写为<script type="math/tex">\mathbf{x}_{16\times1}=\mathbf{C}^T_{16\times4} \mathbf{y}_{4\times1}</script>. 所以,反卷积更好的叫法是转置卷积.</p>

<h3 id="unpooling">Unpooling</h3>
<p>Pooling vs. unpooling in figure below.</p>

<p><img src="/images/unpooling.jpg" alt="unpooling" /></p>

<h1 id="loss">Loss</h1>

<h3 id="focal-loss-2">focal loss [2]</h3>
<p>When approaching the final stage of training, the network is able to handle most of the training cases except for the hard negatives (e.g. those are misclassified). However, the loss caused by the rare hard negatives may be small-valued compared to that caused by well-classified easy ones due to the imbalance in amount. In this way, the easy examples, contributing to the majority of the loss, diminate the gradient and thus mislead training.</p>

<p>Focal loss is defined as</p>

<script type="math/tex; mode=display">\alpha (1-p)^\gamma loss,</script>

<p>where <script type="math/tex">p</script> is the quality of being well classified, <script type="math/tex">\gamma \geq 0</script> is called focusing parameter and <script type="math/tex">\alpha \in [0, 1]</script> is weighting factor. The factoring term <script type="math/tex">(1-p)^\gamma</script> down-weights the loss caused by easy examples (<script type="math/tex">p \approx 1</script>) that have been classified good enough. This in turn increases the importance of correcting misclassified examples (<script type="math/tex">% <![CDATA[
p << 1 %]]></script>).</p>

<h1 id="visualization">Visualization</h1>

<p><strong>MDS</strong> (multi-dimensional scaling) tends to preserve the global structure whereas <strong>T-SNE</strong> tends to retain the local structure.</p>

<h1 id="platform">Platform</h1>

<ul>
  <li>
    <p><a href="/tensorflow-%E5%AD%A6%E4%B9%A0">Tensorflow</a></p>
  </li>
  <li>
    <p><a href="/Caffe">Caffe</a></p>
  </li>
</ul>

<h1 id="reference">Reference</h1>
<p>[1] <a href="https://www.cse.ust.hk/~qyang/Docs/2009/tkde_transfer_learning.pdf">A Survey on Transfer Learning</a></p>

<p>[2] <a href="https://arxiv.org/pdf/1708.02002.pdf">Focal Loss for Dense Object Detection</a></p>


</article>

<div class="page-navigation">
	
    <a class="next" href="/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0" title="NEXT: 读书笔记">&lt;&lt;</a>
		<span> &middot; </span>
  
		<a class="home" href="/" title="Back to Homepage">Home</a>
  
		<span> &middot; </span>
    <a class="prev" href="/image-localization" title="PREV: Image Localization">&gt;&gt;</a>
  
</div>

		</main>
                                                      

		<div class="footer">
<!--  <span class="block">Made with &hearts; using <a href="http://jekyllrb.com/">Jekyll</a> &amp; <a href="https://github.com/heiswayi/the-plain" title="Lei's Blog">The Plain</a> &middot; &lt;/&gt; on <a href="https://github.com/zlthinker" title="Hosted on GitHub">GitHub</a></span> -->
  <span class="block">&copy; 2018 Lei ZHOU</span>
</div>


		

			

		

		<!-- hit counter -->
		<br>
		<center>
		<img src="http://hitwebcounter.com/counter/counter.php?page=6818827&style=0024&nbdigits=5&type=ip&initCount=0" align="top" title="" Alt=""   border="1" height=18px/>    
		</center>  

	</body>

</html>
