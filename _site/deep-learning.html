<!DOCTYPE html>
<html lang="en">

	<head>
		<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1" />


	<title>Deep Learning</title>


<meta name="twitter:card" content="summary" />
<meta name="twitter:site" content="@" />
<meta name="twitter:title" content="Deep Learning" />
<meta name="twitter:description" content="">

<meta name="description" content="">


	<meta name="google-site-verification" content="epFgX0s_0RM3CdjwFcsewfXzPov2g8s9ZBOLyaIUH-o">


<link rel="icon" href="/assets/favicon.png">
<link rel="apple-touch-icon" href="/assets/touch-icon.png">
<link href="https://fonts.googleapis.com/css?family=Karla" rel="stylesheet">
<link rel="stylesheet" href="/assets/core.css">
<link rel="canonical" href="/deep-learning">
<link rel="alternate" type="application/atom+xml" title="Lei Zhou's Blog" href="/feed.xml" />




<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>


		<link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
		<style>
			#taglist {
				color: gray;
				margin: 0;
				margin-top: 16px;
				padding: 0;
				list-style-type: none;
				text-align: center;
				vertical-align: middle;
			}
			#taglist li {
				display: inline;
			}
			#taglist li + li:before {
				content: ", ";
			}
		</style>

		<!-- Google Tag Manager -->
		<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
			new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
			j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
			'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
			})(window,document,'script','dataLayer','GTM-T5S7PZV');</script>
		<!-- End Google Tag Manager -->
	</head>

	<body>
		<!-- Google Tag Manager (noscript) -->
		<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-T5S7PZV"
			height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
		<!-- End Google Tag Manager (noscript) -->

		
<aside class="logo">

	

	<a href="/">
		<img src="/images/avatar.jpeg" class="gravatar">
	</a>
	<span class="logo-prompt">Back to Home</span>

</aside>


		<main>
			<noscript>
	<style>
		article .footnotes {
			display: block;
		}
	</style>
</noscript>

<article>
	<div class="center">
		<h1>Deep Learning</h1>
		<time>March 24, 2018</time>
		<!-- <ul id="taglist">
			Tag:
			
			<li><a href="/tag_index.html" title="deep learning">deep learning</a></li>
			
		</ul> -->
	</div>

	<div class="divider"></div>

	<ul id="markdown-toc">
  <li><a href="#transfer-learning" id="markdown-toc-transfer-learning">Transfer Learning</a></li>
  <li><a href="#lstm" id="markdown-toc-lstm">LSTM</a></li>
  <li><a href="#networks--architectures" id="markdown-toc-networks--architectures">Networks &amp; Architectures</a>    <ul>
      <li><a href="#cnn-networks" id="markdown-toc-cnn-networks">CNN Networks</a></li>
      <li><a href="#dilated-convolution-空洞卷积扩张卷积" id="markdown-toc-dilated-convolution-空洞卷积扩张卷积">Dilated convolution (空洞卷积,扩张卷积)</a></li>
      <li><a href="#deconvolution-反卷积" id="markdown-toc-deconvolution-反卷积">Deconvolution (反卷积)</a></li>
      <li><a href="#unpooling" id="markdown-toc-unpooling">Unpooling</a></li>
      <li><a href="#how-to-compute-receptive-field" id="markdown-toc-how-to-compute-receptive-field">How to compute receptive field?</a></li>
    </ul>
  </li>
  <li><a href="#loss" id="markdown-toc-loss">Loss</a>    <ul>
      <li><a href="#focal-loss-2" id="markdown-toc-focal-loss-2">focal loss [2]</a></li>
    </ul>
  </li>
  <li><a href="#visualization" id="markdown-toc-visualization">Visualization</a></li>
  <li><a href="#platform" id="markdown-toc-platform">Platform</a></li>
  <li><a href="#reference" id="markdown-toc-reference">Reference</a></li>
</ul>

<h1 id="transfer-learning">Transfer Learning</h1>

<p>Transfer learning is dedicated to transfer the knowledge gained from one task to solving other related problems instead of learning from scratch. 
In the field of data representation, an assumption is that the training and future data must be in the same feature space and have the same distribution (actualy they are). In practice, transfer learning has been applied in model initialization whose parameters are shared by different applications like classification, detection, recognition and regression.</p>

<h1 id="lstm">LSTM</h1>

<p><a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/">This</a> excellent post makes me give up writing.</p>

<p><a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/">RNN</a></p>

<h1 id="networks--architectures">Networks &amp; Architectures</h1>

<h3 id="cnn-networks"><a href="/CNN-networks">CNN Networks</a></h3>

<h3 id="dilated-convolution-空洞卷积扩张卷积">Dilated convolution (空洞卷积,扩张卷积)</h3>

<p><img src="/images/dilated_conv.jpg" alt="dilated_conv" />
上图(a)(b)(c)分别是3x3的1-dilated, 2-dilated, 4-dilated conv. Dilated conv设计的目的是不会增加参数的数量的同时增加感受野. 尤其是将(a)(b)(c)级联起来之后,感受野由3x3增加到7x7,再增加到15x15.</p>

<h3 id="deconvolution-反卷积">Deconvolution (反卷积)</h3>

<p>考虑一个4x4的feature map, 经过一个padding 0, stride 1, 3x3的卷积核后变成2x2的feature map, 卷积操作的矩阵运算表达形式为 \(\mathbf{y}_{4\times1}=\mathbf{C}_{4\times16} \mathbf{x}_{16\times1}\). 卷积矩阵\(\mathbf{C}\)的表达式如下:</p>

<p><img src="/images/conv_mat.jpg" alt="conv_mat" /></p>

<p>反卷积数学上其实就是卷积矩阵的转置, 反卷积操作可以写为\(\mathbf{x}_{16\times1}=\mathbf{C}^T_{16\times4} \mathbf{y}_{4\times1}\). 所以,反卷积更好的叫法是转置卷积.</p>

<h3 id="unpooling">Unpooling</h3>
<p>Pooling vs. unpooling in figure below.</p>

<p><img src="/images/unpooling.jpg" alt="unpooling" /></p>

<h3 id="how-to-compute-receptive-field">How to compute receptive field?</h3>

<p><a href="https://medium.com/mlreview/a-guide-to-receptive-field-arithmetic-for-convolutional-neural-networks-e0f514068807">A guide to receptive field arithmetic for Convolutional Neural Networks</a></p>

<h1 id="loss">Loss</h1>

<h3 id="focal-loss-2">focal loss [2]</h3>
<p>When approaching the final stage of training, the network is able to handle most of the training cases except for the hard negatives (e.g. those are misclassified). However, the loss caused by the rare hard negatives may be small-valued compared to that caused by well-classified easy ones due to the imbalance in amount. In this way, the easy examples, contributing to the majority of the loss, diminate the gradient and thus mislead training.</p>

<p>Focal loss is defined as</p>

\[\alpha (1-p)^\gamma loss,\]

<p>where \(p\) is the quality of being well classified, \(\gamma \geq 0\) is called focusing parameter and \(\alpha \in [0, 1]\) is weighting factor. The factoring term \((1-p)^\gamma\) down-weights the loss caused by easy examples (\(p \approx 1\)) that have been classified good enough. This in turn increases the importance of correcting misclassified examples (\(p &lt;&lt; 1\)).</p>

<h1 id="visualization">Visualization</h1>

<p><strong>MDS</strong> (multi-dimensional scaling) tends to preserve the global structure whereas <strong>T-SNE</strong> tends to retain the local structure.</p>

<h1 id="platform">Platform</h1>

<ul>
  <li>
    <p><a href="/tensorflow-%E5%AD%A6%E4%B9%A0">Tensorflow</a></p>
  </li>
  <li>
    <p><a href="/Caffe">Caffe</a></p>
  </li>
</ul>

<h1 id="reference">Reference</h1>
<p>[1] <a href="https://www.cse.ust.hk/~qyang/Docs/2009/tkde_transfer_learning.pdf">A Survey on Transfer Learning</a></p>

<p>[2] <a href="https://arxiv.org/pdf/1708.02002.pdf">Focal Loss for Dense Object Detection</a></p>


	<div class="divider"></div>

	<!-- LikeBtn.com BEGIN -->
	<div class="footer">
		<span class="block">&hearts; <i> I appreciate your feedback! &hearts; </i></span>
	</div>
	<div style="text-align: center;">
		<span class="likebtn-wrapper" data-identifier="Deep Learning"></span>
		<script>(function (d, e, s) { if (d.getElementById("likebtn_wjs")) return; a = d.createElement(e); m = d.getElementsByTagName(e)[0]; a.async = 1; a.id = "likebtn_wjs"; a.src = s; m.parentNode.insertBefore(a, m) })(document, "script", "//w.likebtn.com/js/w/widget.js");</script>
	</div>
	<!-- LikeBtn.com END -->

</article>





<div class="page-navigation">
	
	<a class="next" href="/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0" title="NEXT: 读书笔记">&lt;&lt;</a>
	<span> &middot; </span>
	
	<a class="home" href="/" title="Back to Homepage">Home</a>
	
	<span> &middot; </span>
	<a class="prev" href="/image-localization" title="PREV: Image Localization">&gt;&gt;</a>
	
</div>
		</main>
                                                      

		<div class="footer">
<!--  <span class="block">Made with &hearts; using <a href="http://jekyllrb.com/">Jekyll</a> &amp; <a href="https://github.com/heiswayi/the-plain" title="Lei's Blog">The Plain</a> &middot; &lt;/&gt; on <a href="https://github.com/zlthinker" title="Hosted on GitHub">GitHub</a></span> -->
  <span class="block">
    &copy; 
    2025 
    Lei ZHOU
    <img src="images/dog.jpg" width="35">
  </span>
</div>


		

			

		

		<!-- hit counter -->
		<br>
		<center>
		<!-- <img src="http://hitwebcounter.com/counter/counter.php?page=6818827&style=0024&nbdigits=5&type=ip&initCount=0" align="top" title="" Alt=""   border="1" height=18px/>     -->
		<script type="text/javascript" src="//counter.websiteout.net/js/5/7/10500/1"></script>
		</center>  

	</body>

</html>
